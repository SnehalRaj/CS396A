\documentclass[12pt]{report}
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem*{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newcommand{\Exp}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\bmdeg}{\mathrm{bmdeg}}
\newcommand{\sgn}{\mathrm{sgn}}

\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{quantikz}

\title{Block Multilinear Degree}
\author{Akash Kumar Singh, Siddhant Kar, Snehal Raj\\\\Supervisor: Dr. Rajat Mittal}
\date{}

\begin{document}
\maketitle
\tableofcontents

\chapter{Introduction}
One of the most widely used models to study quantum algorithms is the quantum query model. Many algorithms, ranging from Grover's total search to Shor's famous factoring algorithm, use the quantum query model.

Any algorithm based on the quantum query model queries a Boolean function $x$ repeatedly so that some property of $x$ can be checked at the end. Checking this property can be thought of as calculating another function $f$ on input $x$. The minimum number of queries that any such algorithm must make in order to determine $f$ is called the quantum query complexity $Q_f$ of $f$. The well-known polynomial method puts a lower bound on $Q_f$, by constructing a degree $2Q_f$ polynomial that approximates $f$ up to some $\epsilon$. The minimum degree that any such polynomial can attain is called the $\epsilon$-approximate degree of $f$. Thus, $2Q_f$ is at least equal to the approximate degree of $f$.

Aaronson et al. \cite{paper1} introduced a new notion, where they approximated $f$ up to $\epsilon$ using a very specific kind of polynomial of degree $2Q_f$, called a block-multilinear polynomial. The minimum degree attainable by such a polynomial is called the $\epsilon$-approximate block-multilinear degree. This notion of block-multilinear polynomials was used in \cite{paper1} to solve a problem called Forrelation. Forrelation has achieved the largest gap between quantum and classical query complexities known yet among promise problems. A \textit{promise} problem is a problem where there is some condition on the input function $x$ and so we calculate $f(x)$ only for a limited number of $x$, for example, Simon's problem.

It is easy to see that the $\epsilon$-approximate block-multilinear degree is at least equal to the $\epsilon$-approximate degree. The former may hence be closer to query complexity. Aaronson et al. \cite{paper2} showed an equivalence between degree 2 block-multilinear polynomials that approximate $f$ and 1-query quantum algorithms for $f$. This, however, does not hold for higher degrees. They also showed an equivalence between general and block-multilinear degree up to some loss in the quality of approximation.

We mainly worked on the gap between the exact degree and exact block-multiliear degree of $f$. The exact block-multilinear degree is simply the 0-approximate block-multilinear degree. This is well-defined since $f$ is a Boolean function, that is, we can always write $f$ as a polynomial using indicator functions, which can then easily be converted to a block-multilinear polynomial of larger degree. We tried separating these two degrees by using two different approaches, symmetrization and dual witness. The details can be found in Chapter 3. We also present the main results of \cite{paper1} in Chapter 4.

\chapter{Preliminaries}
In this chapter, we give an overview of the basics of quantum mechanics and the quantum query model, and then we proceed to formally define block-multilinear degree and the Forrelation problem.

\section{Quantum Mechanics}
The postulates of quantum mechanics state that any quantum mechanical system can be quantized to the set of eigenstates of its observables. One of the most basic quantum mechanical systems is a simple 2-state system called the qubit. The qubit is a linear superposition of two states, $|0\rangle$ and $|1\rangle$, which form an orthonormal basis of the qubit space. We thus write the state of the qubit as $$|\psi\rangle = \alpha|0\rangle + \beta|1\rangle$$ where $\alpha$ and $\beta$ are called the amplitudes and can be complex numbers in general. Like any observable, measuring this qubit must result in one of the basis states, with probability equal to the square of the corresponding amplitude. Thus, we have $$\alpha^2 + \beta^2 = 1.$$ A quantum system can be thought of as having several of such qubits, and its state can be expressed as the tensor product of all of its qubit states. The postulates also state that the evolution of any quantum state must be linear and unitary, and thus any operation on a set of $n$ qubits must be of the form $$U|\psi\rangle = \alpha_0 U|0^{\otimes n}\rangle + \ldots + \alpha_{2^n-1} U|1^{\otimes n}\rangle$$ where $U$ is a unitary $n \times n$ matrix. These operations are performed using quantum \textit{gates}, similar to logic gates in classical computing, and they can be used to build quantum \textit{circuits}. With this, we can now talk about the quantum query model.

\section{Quantum Query Model}
The quantum query model is the most widely used model to study quantum algorithms. Given a boolean function $x$, we are required to calculate a property $f(x)$ by querying $x$. The function $x$ may either be partial (promise problem) or total (total problem). A partial function has some condition on its outputs and hence can be constructed using fewer inputs, whereas a total function has no such restriction.

For our convenience, we assume $x$ is a function from $\{-1,1\}^n$ to $\{-1,1\}$. Let us represent it in truth table form as $x = (x_1, \ldots, x_N)$, where $N = 2^n$ and each $x_i \in \{-1,1\}$ corresponds to the $i$th output. We assume that we only want to answer a yes/no question about $x$. Thus, we wish to calculate $$f\colon \{-1,1\}^N \longrightarrow \{0,1\}.$$

We are given access to an oracle or black box $O_x$ which is a quantum gate that, on input $|i\rangle$ and control qubit $b$, does either of the following.

\begin{center}
\begin{quantikz}
\lstick[wires=2]{$\ket{i}$} & \gate[wires=3]{O_x} & \qw \rstick[wires=2]{$\ket{i}$} \\
&  & \qw \\
\lstick{$\ket{b}$} &  & \qw \rstick{$\ket{b \oplus x_i}$}
\end{quantikz}
\begin{quantikz}
\lstick[wires=2]{$\ket{i}$} & \gate[wires=3]{O_x} & \qw \rstick[wires=3]{$x_i\ket{i}\ket{b}$} \\
&  & \qw \\
\lstick{$\ket{b}$} &  & \qw
\end{quantikz}
\end{center}

Both the oracles shown above are equivalent. For example, to convert the first to the second, we set the control bit $|b\rangle$ to $\frac{1}{\sqrt{2}}(|1\rangle - |-1\rangle)$. We will only use the latter oracle that takes $|i\rangle$ and returns $x_i |i\rangle$. Our quantum query algorithm can call the oracle several times and also perform other linear operations in between as shown below.

\begin{center}
\begin{quantikz}
\lstick[wires=2]{$\ket{i}$}
& \gate[wires=4]{U_0} & \gate[wires=4]{O_x}
& \gate[wires=4]{U_1} & \gate[wires=4]{O_x}
& \ \ldots\ \qw
& \gate[wires=4]{U_{t-1}} & \gate[wires=4]{O_x}
& \gate[wires=4]{U_t} & \meter{} \\
&&&& & \ \ldots\ \qw &&&& \meter{} \\
\lstick[wires=2]{$\ket{w}$} &&&& & \ \ldots\ \qw &&&& \meter{} \\
&&&& & \ \ldots\ \qw &&&& \meter{}
\end{quantikz}
\end{center}

The gates in between the oracles are fixed and do not vary with $x$. Out of all possible combinated states of the qubits at the end of the algorithm, we call only a few of these states $\textit{accepting}$ states. If the final measurement gives one of these states, the algorithm outputs 1, else it outputs 0. The algorithm should output $1$ with high probability if $f(x)=1$ and output $0$ with high probability if $f(x)=0$. More formally, for $\epsilon \geq 0$,
\[
\Pr[\text{Algorithm outputs 1}] \in \begin{cases}
    [1 - \epsilon, 1] & \text{ if }f(x) = 1 \\
    [0, \epsilon] & \text{ if }f(x) = 0.
\end{cases}
\]
The number of calls $t$ to the oracle $O_x$ is called the query complexity of the algorithm. The query complexity $Q_f$ of $f$, as discussed eariler, is the minimum possible query complexity of any such algorithm that calculates $f$.

\section{Block-multilinear degree}
We now formally define block-multilinear polynomials and block-multilinear degree.

\begin{definition}
A block multilinear polynomial on $\{-1,1\}^n$ is a polynomial of the form $$p(x) = p(x_{1,1}, x_{1,2}, \ldots) = \sum_{(i_1, \ldots, i_k)} a_{i_1 \ldots i_k} x_{1,i_1} \ldots x_{k,i_k}$$ where its $n$ variables can be partitioned insto $k$ disjoint blocks $B_i, i \in [k]$, such that $x_{i,j} \in B_i ~\forall j$. 
\end{definition}

\begin{definition}
Let $\epsilon \geq 0$. A boolean function $f\colon \{-1,1\}^N \rightarrow \{0,1\}$ is said to have $\epsilon$-approximate block-multilinear degree, denoted $\bmdeg_\epsilon(f)$, equal to $d$ if $d$ is the minimum degree a block-multilinear polynomial $p\colon \{-1,1\}^{Nk} \rightarrow [-1,1]$ can have so that $$
|p(x, \ldots x) - f(x)| \leq \epsilon ~\forall x \in \{-1,1\}^N.
$$
\end{definition}

Given any quantum query algorithm for $f$ with complexity $t$, we can construct a block-multilinear polynomial of degree $2t$ that approximates $f$. This implies that we can have a degree $2Q_f$ block-multilinear approximation for $f$ up to some $\epsilon$, and hence $2Q_f$ must be at least equal to $\bmdeg_\epsilon(f)$. The following theorem, with proof, is a rephrased version of the result in \cite{paper1}.

\begin{theorem}
The probability that a quantum query algorithm of complexity $t$ accepts a function $x \in {-1,1}^N$ is given by $p(x, x, \ldots)$, where $p$ is a block multilinear polynomial with $2t$ blocks of size $N$ each, and $p(\bar{x})$ is bounded in $[-1,1]$.
\end{theorem}
\begin{proof}
Consider the query model discussed above. Let $x_{j,i}$ denote the value of $x_i$ returned on the $j$th query to the oracle. We first prove that the amplitudes of the final state after $t$ queries are block-multilinear in $x_{1,1}, \ldots, x_{t,N}$. We prove this using induction on $t$.

When $t=0$, the amplitudes are simply given by constant polynomials. Let the result hold for $t-1$ queries. So now, the state of the qubits after the gate $U_{t-1}$ is given by
$$\sum_{i,w} a_{i,w}(x_{1,1}, \ldots, x_{t-1,N}) |i\rangle |w\rangle.$$
After applying $O_x$, the state is
$$\sum_{i,w} x_{t,i} a_{i,w}(x_{1,1}, \ldots, x_{t-1,N}) |i\rangle |w\rangle.$$

It is easy to see that the amplitudes are still block-multilinear, now with $t$ blocks, even after the linear transformation $U_t$. The squares of the amplitudes are also block-multilinear, but with $2t$ blocks. We simply introduce a duplicate variable $x_{t+j,i}$ for each $x_{j,i}$ and then square amplitudes as shown below. The final polynomial $p(\bar{x})$ is given by
$$\sum_{i,w \in Acc} |a_{i,w}(x_{1,1}, \ldots, x_{t,N})|^2 = \sum_{i,w \in Acc} a^*_{i,w}(x_{1,1}, \ldots, x_{t,N}) a_{i,w}(x_{t+1,1}, \ldots, x_{2t,N})$$
which is clearly block multilinear. The probability that the algorithm accepts is simply $p(x, x, \ldots)$. Since this must lie in $[0,1]$, the vector of accepting state amplitudes has norm at most 1. It is easy to see that $p(\bar{x})$ must therefore lie in $[-1,1]$.
\end{proof}


\section{Forrelation}
Finally, we define Forrelation. Intuitively, it is a measure of the correlation between a function $f$ and the fourier transform of a second function $g$. Given oracle access to two boolean functions $f,g\colon \{0,1\}^{n} \rightarrow  \{-1,1\}$, let
\begin{equation}
\Phi_{f, g} := \frac{1}{2^{3n/2}} \sum_{x, y \in \{0,1\}^{n}} f(x)(-1)^{x \cdot y} g(y).
\end{equation}
The problem is to decide whether $\Phi_{f,g} \geq 0.6$ or $\left|\Phi_{\mathrm{f}, \mathrm{g}}\right| \leq 0.01$, and we are promised that one of these is the case.

$k$-fold Forrelation is a more general problem, where we are given oracle access to $k$ boolean functions $f_1, \ldots, f_k\colon \{0,1\}^n \rightarrow \{-1,1\}$ and
\begin{equation}
\Phi_{f_1, \ldots, f_k} := \frac{1}{2^{(k+1)n/2}} \sum_{x_1, \ldots, x_k \in \{0,1\}^n} f_1(x_1)(-1)^{x_1 \cdot x_2} f_2(x_2) \ldots (-1)^{x_{k-1} \cdot x_k} f_k(x_k)
\end{equation}
is promised to be either at least 0.6 or at most 0.01 in magnitude. The problem is again to decide which is the case. This problem can also be defined using the following circuit, which solves it in $k$ queries.

\begin{center}
\begin{quantikz}
\lstick{$\ket{0}$}
& \gate{H} & \gate[wires=3]{O_{f_1}}
& \gate{H} & \ \ldots\ \qw
& \gate{H} & \gate[wires=3]{O_{f_k}}
& \gate{H} & \meter{} \\
\lstick{$\ket{0}$}
& \gate{H} && \gate{H} & \ \ldots\ \qw & \gate{H} && \gate{H} & \meter{} \\
\lstick{$\ket{0}$}
& \gate{H} && \gate{H} & \ \ldots\ \qw & \gate{H} && \gate{H} & \meter{} \\
\end{quantikz}
\end{center}

The Hadamard gate $H$ is a linear operation that transforms $|0\rangle$ to $\frac{1}{\sqrt{2}}(|0\rangle + |1\rangle)$ and $|1\rangle$ to $\frac{1}{\sqrt{2}}(|0\rangle - |1\rangle)$. It can be shown that $H^{\otimes n}$ corresponds to a Fourier transform. It can hence also be shown that the probability of finally measuring $|0\rangle^{\otimes n}$ in the above circuit is exactly $\Phi_{f_1, \ldots, f_k}$.

As shown in \cite{paper1}, the complexity can be further improved to $\lfloor k/2 \rfloor$ queries. It is also shown in \cite{paper1} that Forrelation takes at least $\Omega(\sqrt{N}/\log N)$ classical queries to solve, where $N = 2^n$. There is thus a gap of $\Omega(\sqrt{N}/\log N)$ between classical and quantum complexities for this problem. Interestingly, the block-multilinear polynomial corresponding to this problem can be used to solve it in $O(\sqrt{N})$ classical queries, meaning that the gap is indeed optimal. We will go through this proof in the last chapter.




\chapter{Block-multilinear Degree}
In this chapter, we try comparing the exact block-multilinear degree of a Boolean function to its degree. It is easy to see that the former is at least equal to the latter. We are interested in the gap between the two and want to find a function $f$ for which the inequality is strict, that is, $\bmdeg_\epsilon(f) > \deg_\epsilon(f)$.

Aaronson et al. \cite{paper2} made a construction from any given polynomial $p\colon \{-1,1\}^{N} \rightarrow [-1,1]$ of degree $d$ to a $d$-block-multilinear polynomial $\tilde{p}\colon \{-1,1\}^{(N+1) d} \rightarrow [-c_d, +c_d]$ such that $\tilde{p}(1,x, \ldots, 1,x) = p(x)$ for all $x \in\{-1,1\}^{N}$ and $c_d$ is a constant depending only on $d$. We take a similar approach and attempt to construct a block-multilinear polynomial by symmetrically splitting the coefficients of a given polynomial. We also try a second approach which involves finding a dual witness for a suitable linear program.

\section{Symmetrization}
Suppose we are given the exact polynomial representation of $f\colon \{-1,1\}^N\rightarrow \{-1,1\}$, of degree $d$. In the Fourier basis, this is given by
\begin{equation}
    f(x) = \sum_{S\subseteq [n]} \hat{f}(S) \chi_S(x)
\end{equation}
where $\chi_S(x) = \prod_{i\in S}x_i$ is the $S$th Fourier function. We equally split each monomial $\hat{f}(S) \chi_S(x)$ into monomials of block-multilinear form. Let
\begin{equation}
S_{(i_1, \dots, i_k)} := \{i\colon i = i_j\text{ for an odd number of }j\} \setminus \{0\}
\end{equation} and $I_S := \{m\in \{0, \ldots, n\}^d\colon S_m = S\}$. Then $f_{sym}\colon \{-1,1\}^{(N+1)d} \rightarrow \mathbb{R}$ is defined as
\begin{equation}
    f_{sym}(\bar{x}) := \sum_{S\subseteq [n]} \sum_{m\in I_S} \frac{\hat{f}(S)}{|I_S|} \chi_m(\bar{x})
\end{equation}
for $\bar{x}\in \{-1,1\}^{(N+1)d}$. We can alternatively define $\tilde{f}_{sym}$ using
\begin{equation}
    \tilde{S}_{(i_1, \dots, i_k)} := \{i\colon i = i_j\text{ for exactly one }j\} \setminus \{0\}.
\end{equation}

Notice that for any $x \in \{-1,1\}^{N}$, we have
\begin{equation}
    \chi_m(1,x, \ldots, 1,x) = \chi_{S_m}(x)
\end{equation}
since $S_m$ consists of only those $i$ which occur an odd number of times in $m$. If $i$ occurs an even number of times in $m$, then $x_i$ gets squared up in $\chi_m(1,x, \ldots, 1,x)$ and so does not appear in $\chi_{S_m}(x)$. Hence, both the constructions satisfy
\begin{equation}
    f_{sym}(1,x, \ldots, 1,x) = f(x)
\end{equation}
for all $x \in \{-1,1\}^N$. The only thing that is left to check is whether this polynomial is bounded in $[-1,1]$ on all $\bar{x} \in \{-1,1\}^{(N+1)d}$. To do this, it is enough to find the minimum value attained by $f_{sym}$ since it takes identical values on both sides of 0. If this value is at least -1, then $f_{sym}$ is bounded in [-1,1].

\subsection{A Counter-example}
Given a function $f\colon \{-1,1\}^n \rightarrow \mathbb{R}$
$$
f(x) = \sum_{S\subseteq [n]} a_{S} \prod_{i\in S}x_i
$$
where $x\in \{-1,1\}^n$, the minimum value it attains is given by the following Integer Linear Program:
\begin{align*}
\text{min } & \sum_{S\subseteq [n]} a_{S}(1-2y_S) \\
\text{s.t. } & y_S+2z_S=\sum_{i\in S} x_i ~\forall S\subseteq [n] \\
& y_S\in \{0,1\} ~\forall S\subseteq [n] \\
& x_i \in \{0,1\} ~\forall i \in [n] \\
& z_S\in \mathbb{Z}.
\end{align*}
Using this ILP to check $f_{sym}$ for all $f\colon \{-1,1\}^N \rightarrow \{-1,1\}$ of degree 2 and 3, we found the following counter-example:
$$f(x_1, x_2, x_3) = -0.5+0.5x_1x_2-0.5x_1x_3-0.5x_2x_3.$$
Here, $d = 2$ and $N = 3$. After symmetrization, we get
\begin{align*}
f_{sym}(\bar{x})=&-0.125x_{10}x_{20}-0.125x_{11}x_{21}-0.125x_{12}x_{22}-0.125x_{13}x_{23} \\
&+0.25x_{11}x_{22}+0.25x_{12}x_{21} \\
&-0.25x_{11}x_{23}-0.25x_{13}x_{21}-0.25x_{12}x_{23}-0.25x_{13}x_{22}  
\end{align*}
where $\bar{x} \in \{-1,1\}^8$. This function takes value -1.25 at the following valuation:
\[\begin{array}{c c}
x_{10} = -1.0 & x_{20} = -1.0 \\
x_{11}= 1.0 & x_{21} = -1.0 \\
x_{12} = 1.0 & x_{22} = -1.0 \\
x_{13} = -1.0 & x_{23} = 1.0.
\end{array}\]
The alternative construction gives
\begin{align*}
\tilde{f}_{sym}(\bar{x})=&-0.5x_{10}x_{20}+0.25x_{11}x_{22}+0.25x_{12}x_{21}-0.25x_{11}x_{23} \\
&-0.25x_{13}x_{21}-0.25x_{12}x_{23}-0.25x_{13}x_{22}
\end{align*}
where $\bar{x} \in \{-1,1\}^8$. This function takes value -2 at the following valuation:
\[\begin{array}{c c}
x_{10} = -1.0 & x_{20} = -1.0 \\
x_{11}= 1.0 & x_{21} = -1.0 \\
x_{12} = 1.0 & x_{22} = -1.0 \\
x_{13} = -1.0 & x_{23} = 1.0.
\end{array}\]
Thus, unfortunately, our construction is incorrect. The program we used to find
the counter-example can be accessed  \href{https://gist.github.com/akashks1998/f00e1204654503b99a78cd05374819b1}{here}, and for the alternative construction can be accessed \href{https://gist.github.com/akashks1998/8147d12f40da6534a7f70be3d18fee02}{here}.

\section{Dual Witness}
We now try another approach. Consider the linear program given below, where we find the best possible approximation of a function $f\colon \{-1,1\}^N \rightarrow \{0,1\}$ using block-multilinear polynomials $g$ of degree $d = \deg(f)$. If the value of its dual is strictly greater than $\epsilon_0$, then by weak duality, the value of the primal is greater than $\epsilon_0$ as well, and thus $\bmdeg_{\epsilon_0}(f) > d$.
\begin{align*}
    \text{min } & \epsilon \\
    \text{s.t. } & f(x) - g(x, \ldots, x) \leq \epsilon ~\forall x\\
    & g(x, \ldots, x) - f(x) \leq \epsilon ~\forall x\\
    & g(\bar{x}) \leq 1 ~\forall \bar{x}\\
    & -1 \leq g(\bar{x}) ~\forall \bar{x}
\end{align*}
The variables here are $\epsilon$ and the coefficients of $g$. The dual for this program is
\begin{align*}
    \text{max } & F(\phi, \psi_1, \psi_2) := \sum_x \phi(x)f(x) - \sum_{\bar{x}} (\psi_1(\bar{x}) + \psi_2(\bar{x})) \\
    \text{s.t. } & \left|\sum_x \phi(x)\right| = 1 \\
    & \psi_1(\bar{x}), \psi_2(\bar{x}) \geq 0 ~\forall \bar{x} \\
    & {\hat{\psi}}_1(m) - {\hat{\psi}}_2(m) = \frac{N}{2^{(N+1)d}} \hat{\phi}(S_m) ~\forall m\in \{0, \ldots, N\}^d
\end{align*}
where the vectors $\phi$, $\psi_1$ and $\psi_2$ are the variables. If there exists a feasible $(\phi$, $\psi_1$, $\psi_2)$ such that $F(\phi, \psi_1, \psi_2) > \epsilon_0$, then the value of the dual is greater than $\epsilon_0$ and hence $\bmdeg_{\epsilon_0}(f) > d$. The converse holds as well 
by strong duality, hence the following result.

\begin{theorem}
Let $f\colon \{-1,1\}^N \rightarrow \{0,1\}$ have degree $d$. Then $\bmdeg_{0}(f) > d$ if and only if there exist $\phi\colon \{-1,1\}^N \rightarrow \mathbb{R}$ and $\psi_1, \psi_2\colon \{-1,1\}^{(N+1)d} \rightarrow \mathbb{R^+}$ such that \begin{enumerate}
    \item $\sum_x \phi(x)f(x) \geq \sum_{\bar{x}} (\psi_1(\bar{x}) + \psi_2(\bar{x})).$
    \item ${\hat{\psi}}_1(m) - {\hat{\psi}}_2(m) = \frac{N}{2^{(N+1)d}} \hat{\phi}(S_m) ~\forall m\in \{0, \ldots, N\}^d.$
\end{enumerate} 
\end{theorem}





\chapter{Classical-Quantum Gap}
In this chapter, we give an overview of the two results in \cite{paper1}. The results are stated below.

\begin{theorem}
Any classical randomized algorithm for Forrelation must make $\Omega(\frac{\sqrt{N}}{\log N})$ queries.
\end{theorem}

\begin{theorem}
Let $Q$ be any quantum algorithm that makes $t = O(1)$ queries to an $N$-bit string $X \in \{0,1\}^{N}$. Then we can estimate $\Pr[Q\text{ accepts }x]$, to constant additive error and with high probability, by making only $O(N^{1 - 1/2t})$ classical randomized queries to $X$. Moreover, the randomized queries are nonadaptive.
\end{theorem}

\section{Randomized Lower Bound}
We saw earlier that Forrelation can be solved using $O(1)$ queries. The result states that any classical randomized algorithm for must make $\Omega(\frac{\sqrt{N}}{\log N})$ queries, therefore implying a separation of order $\Omega(\frac{\sqrt{N}}{\log N})$ between quantum and classical complexities. We give a brief overview of the proof.

\subsection{Real Forrelation}
The first step to prove the randomized lower bound is to convert the Forrelation problem into a Real Forrelation problem. In Real Forrelation, we are given oracle access to two real functions $f,g\colon \{0,1\}^{n}\rightarrow \mathbb{R}$ and are promised that either
\begin{enumerate}
\item every f(x) and g(y) value is an independent $\mathcal{N}(0,1)$ Gaussian, or else
\item every f(x) value is an independent $\mathcal{N}(0,1)$ Gaussian and every g(y) value equals $\hat{f}(y)$ (i.e. the Fourier transform of $f$ evaluated at $y$).
\end{enumerate}
The problem is to decide which holds.

It can be proved that if there exists a $T$-query algorithm that solves Forrelation with bounded error, then there also exists an $O(T)$-query algorithm that solves Real Forrelation with bounded error. The details of this reduction can be found in \cite{paper1}. Thus, we only need to prove a lower bound on Real Forrelation.

\subsection{Gaussian Distinguishing}
In the Gaussian Distinguishing problem, we are given oracle access to a collection of $\mathcal{N}(0,1)$ real Gaussian variables $x_{1},x_{2}..., x_{m}$ and are asked to decide whether 
\begin{enumerate}
\item the variables are all independent, or
\item the variables lie in a known low dimensional subspace $S \leq R^{m}$ such that there is a covariance of at most $\epsilon$ between each pair of variables, i.e., $ |~Cov(x_{i},x_{j})~| \leq \epsilon ~\forall i,j$.
\end{enumerate}
We finally have the following result for Gaussian Distinguishing in \cite{paper1}.

\begin{theorem}
Gaussian distinguishing requires $\Omega\left(\frac{1 / \varepsilon}{\log (M / \varepsilon)}\right)$ classical randomized queries.
\end{theorem}

The proof depends on the intuition that because the real gaussian variables have restricted covariances and thus are nearly orthogonal. So, if we restrict our attention to any subset $S$ of $R^{m}$, their correlations are weak i.e. the variables satisfy an "orthogonal approximation". Now, to solve the Gaussian Distinguishing problem, we need to assess the number of queries required till the "orthogonal approximation" breaks down.

Using Gram-Schmidt orthogonalization and Gaussian Azuma's inequality, it can be shown that that the first $\Omega\left(\frac{1 / \varepsilon}{\log (M / \varepsilon)}\right)$ query responses are close to independent Gaussians and thus Gaussian distinguishing requires at least that many queries. Thus, using this bound on Gaussian Distinguishing, and setting $M$ to $2N$ and $\epsilon$ to $1/\sqrt{N}$, we get the lower bound on Real Forrelation.



\section{Optimal Randomized Algorithm}
Previously, we stated that solving Forrelation requires just one quantum query. This single-query quantum algorithm can in fact be converted to a $\sqrt{N}$-query randomized algorithm, by approximating the block-multilinear polynomial corresponding to the algorithm. We present a rephrased proof of this result from \cite{paper1}.

\begin{theorem}
Every degree-$k$ polynomial $p\colon \{-1,1\}^{N} \rightarrow \mathbb{R}$ that is \begin{enumerate}
    \item bounded in $[-1,1]$ at every Boolean point, and
    \item "block-multilinear" (that is, the variables can be partitioned into $k$ blocks, such that every monomial is the product of one variable from each block),
\end{enumerate} can be approximated to within $\pm \epsilon$, with high probability, by nonadaptively querying only $O\left(N^{1 - 1/2t}\right)$ of the variables.
\end{theorem}



\subsection{The Estimator}
Given $x \in \{-1,1\}^{(n+1)k}$, we need to estimate the block-multilinear polynomial
\begin{equation}
p(x) := \sum_{i_1, \ldots, i_k} a_{i_1, \ldots, i_k} x_{1,i_1} \ldots x_{k,i_k}.
\end{equation}
We define the estimator as
\begin{equation}
P := n\sum_{i_1, \ldots, i_k} y_{1,i_1} \ldots y_{k,i_k} b_{i_1, \ldots, i_k}(x)
\end{equation}
where
\begin{equation}
b_{i_1, \ldots, i_k}(x) := a_{i_1, \ldots, i_k} x_{1,i_1} \dots x_{k,i_k}
\end{equation} and the random variables $y_{j,i}$ are independent and take values $\{0,1\}$ with $\Pr[y_{j,i} = 1] = \frac{1}{n^{1/k}}$. By linearity of expectation, we have
\begin{equation}
\Exp[P] = p(x).
\end{equation}

Now let us say we sample $P$ $m$ times. We want $m$ to be $O(1)$. Let $\tilde{P}$ be the mean of this sample. By the strong law of large numbers, $\tilde{P}$ converges to $p(x)$ with variance $\Var[P]/m$. By Chebyshev's inequality, we have
\begin{equation}
\Pr[~|\tilde{P} - p(x)| \leq \epsilon~] \leq \frac{\Var[P]}{m \epsilon^2}.
\end{equation}
Hence, for convergence with high probability in $m = O(1)$ steps, $\Var[P]$ must be $O(1)$ as well. This is what we will prove next. Each step requires us to query only those $x_{j.i}$ for which $y_{j,i} = 1$. This is on expectation $n/n^{1/k}$ (by linearity of expectation), that too with high probability (by the Chernoff bound). Thus, the algorithm requires $O(n^{1-1/k})$ queries.

\subsection{Bound on Variance}
We give a simplified version of the proof in \cite{paper1}.
\begin{equation*}
\begin{split}
\Var[P] = & \sum_{i_1, \ldots, i_k, i'_1, \ldots, i'_k \in [n]} b_{i_1, \ldots, i_k}(x) \cdot b_{i'_1, \ldots, i'_k}(x) \cdot \Cov[y_{1 i_1} \ldots y_{k,i_k}, y_{1,i'_1} \ldots y_{k,i'_k}] \cdot n^2
\\
= & \sum_{S \subseteq [k]} \left(\sum_{i,i'\colon i_j = i'_j \iff j \in S} b_{i_1, \ldots, i_k}(x) \cdot b_{i'_1, \ldots, i'_k}(x) \left(\frac{n^{|S|/k}}{n^2} - \frac{1}{n^2}\right) n^2\right)
\\
= & \sum_{S \subseteq [k]} \left((n^{|S|/k} - 1) \sum_{i,i'\colon i_j = i'_j \iff j \in S} b_{i_1, \ldots, i_k}(x) \cdot b_{i'_1, \ldots, i'_k}(x)\right)
\\
= & \sum_{S \subseteq [k]} \left(\sum_{T \subseteq S} (-1)^{|S| - |T|} (n^{|T|/k} - 1)\right) \sum_{i,i'\colon j \in S\implies i_j = i'_j} b_{i_1, \ldots, i_k}(x) \cdot b_{i'_1, \ldots, i'_k}(x)
\end{split}
\end{equation*}

The last two steps follow from the inclusion-exclusion principle. Let $I_{S}$ be the set of all $i_1, \ldots,  i_k, i'_1, \ldots i'_k$ such that $i_j = i'_j$ for at least $j \in S$, and $J_{S}$ be such that $i_j = i'_j$ if and only if $j \in S$. By inclusion-exclusion, we have
\begin{equation*}
|J_{S}| = |I_{S}| - \left(\sum_{T \supset S\colon |T| = |S|+1} |I_{T}|\right) + \left(\sum_{T \supset S\colon |T| = |S|+2} |I_{T}|\right) \ldots,
\end{equation*}
so multiplying each equation on both sides by $(n^{|S|/k} - 1)$ and adding them together gives us the desired result. The coefficient of $|I_{T}|$ in the RHS is equal to $\sum_{S \subseteq T} (-1)^{|T| - |S|} (n^{|S|/k} - 1)$. Let us now define the quantity
\begin{equation}
\Lambda_S(x) := \sum_{(i_j)_{j \in S}} \left(\sum_{(i_j)_{j \notin S}} b_{i_1, \ldots, i_k}(x)\right)^2
\end{equation}
and let $\Lambda_S \leq \delta$ for each $S$. Then, we have
\begin{equation*}
\Var[P] = \sum_{S \subseteq [k]} \left(\sum_{T \subseteq S} O(n^{|T|/k})\right) \cdot O(\delta) = O(\delta n).
\end{equation*}

Hence, $\delta$ must be $O(1/n)$, say $\epsilon^2/n$, for some $\epsilon$. So for any $x$, $\Lambda_S(x) \leq \epsilon^2/n$ for all $S$. The initial polynomial should be preprocessed so that this holds.

\subsection{Preprocessing}
The approach is to prove that for any $S \subseteq [k]$,
$$
\sum_{(i_j)_{j \in S}} \left(\sum_{(i_j)_{j \notin S}} a_{i_1, \ldots, i_k}\right)^2 \leq \delta.
$$
The method used to prove this is to split each variable $x_{j,i}$ into some $m$ new variables and replace it with $(x_{j,i'_1} + \ldots + x_{j,i'_m})/m$. We initially have the $k$-block-multilinear polynomial
\begin{equation}
p(x) := \sum_{i_1, \ldots, i_k} a_{i_1, \ldots, i_k} x_{1,i_1} \ldots x_{k,i_k}
\end{equation}
where $i_j \in [N]$ $\forall j \in [k]$. First, we want to show that we can split the variables so that
$$
\Lambda_{[k]} = \sum_{(i_j)_{j \in [k]}} a_{i_1, \ldots, i_k}^2 \leq \delta.
$$
Next, if $S = \{j_1, \ldots, j_l\} \neq [k]$, we put $x_{j,i} = 1$ for $j \notin S$ in the polynomial. Then we have
$$
\tilde{p}(x_{j_1,1}, \ldots, x_{j_l,N}) = \sum_{i_{j_1}, \ldots, i_{j_l}} a'_{i_{j_1}, \ldots, i_{j_l}} x_{j_1,i_{j_1}} \ldots x_{j_l,i_{j_l}}
$$
where $a'_{i_{j_1}, \ldots, i_{j_l}} = \sum_{(i_j)_{j \notin S}} a_{i_1, \ldots, i_k}$. Hence, after splitting the new polynomial $\tilde{p}$,
$$
\Lambda_S = \sum_{(i_j)_{j \in S}} \left(\sum_{(i_j)_{j \notin S}} a_{i_1, \ldots, i_k}\right)^2 = \sum_{i_{j_1}, \ldots, i_{j_l}} (a'_{i_{j_1}, \ldots, i_{j_l}})^2 \leq \delta.
$$
Since each splitting only either decreases $\Lambda_S$ for each $S$ or keeps it constant, we can repeat it for each subset $S$. If each splitting introduces $m$ new variables, we eventually have $2^k m$ new variables. Since the total number of variables $n$ per block should stay $O(N)$, $m$ should be $O(N)$ or $O(1/\delta)$.

\begin{lemma}
We can introduce $O(1/\delta)$ new variables by variable splitting, such that for the resulting polynomial, we have
$$
\sum_{(i_j)_{j \in [k]}} a_{i_1, \ldots, i_k}^2 \leq \delta.
$$
\end{lemma}

The above lemma from \cite{paper1} completes the proof. However, we found a small inaccuracy. Suppose the lemma is correct. We split each $x_{j,i}$ into $1 + m_{j,i}$ variables. Let $m_{j,i} = \lfloor f_j(i)/\delta \rfloor$. Then we have
$$
\delta m_{j,i} \leq f_j(i) \leq \delta (1 + m_{j,i}).
$$
The new sum of coefficients squared is
$$
\sum_{(i_j)_{j \in [k]}} \frac{a_{i_1, \ldots, i_k}^2}{(1 + m_{1,i_1}) \ldots (1 + m_{k,i_k})} \leq \delta^k \sum_{(i_j)_{j \in [k]}} \frac{a_{i_1, \ldots, i_k}^2}{f_1(i_1) \ldots f_k(i_k)}
$$
and it must be at most $\delta$. Hence, we must have
$$
\frac{1}{N^{k-1}} \sum_{(i_j)_{j \in [k]}} \frac{a_{i_1, \ldots, i_k}^2}{f_1(i_1) \ldots f_k(i_k)} \leq \frac{1}{(\delta N)^{k-1}} = O(1).
$$
Also, the total number of new variables is $\sum_{j, i} m_{j,i} \leq (1/\delta) \sum_{j, i} f_j(i)$. For this to be $O(1/\delta)$, we must also have $\sum_{j, i} f_j(i) = O(1)$. Then
\begin{equation*}
\frac{\frac{1}{N^{k-1}} \left(\sum_{(i_j)_{j \in [k]}} \frac{a_{i_1, \ldots, i_k}^2}{f_1(i_1) \ldots f_k(i_k)} + \sum_{j, i} N^{k-1} f_j(i)\right)}{(1+k)\cdot N^k} \geq \frac{1}{N^{k-1}} \left(\prod_{(i_j)_{j \in [k]}} a_{i_1, \ldots, i_k}^2\right)^\frac{1}{(1+k) \cdot N^k}
\end{equation*}
using the AM-GM inequality. If $a_{i_1, \ldots, i_k}^2 = \frac{1}{N^k}$ for each $(i_1, \ldots, i_k)$, then we have
$$
O(1) \geq (1+k)\cdot N^\frac{1}{1+k}
$$ which is a contradiction. We conjecture that this is possible even though $p(x)$ has to be bounded in [-1,1] on all $x$.

\chapter{Conclusion}
We discussed the notion of block-multilinear degree, and compared it to the general degree. We tried to check if $\deg(f)$ and $\bmdeg_0(f)$ are equivalent notions, by constructing a block-multilinear $f_{sym}$ from any given $f$. However, we found that the construction was incorrect since it was not bounded in [-1,1]. It is still not clear if $\deg(f)$ and $\bmdeg_0(f)$ are separate, since we only showed unboundedness for symmetric block-multilinear polynomials. However, we now also have a condition for separating $\deg(f)$ and $\bmdeg_0(f)$ using the dual witness.

\section{Future Work}
There is a lot of scope for future work related to block-multilinear degree. We can try constructing block-multilinear polynomials that are non-symmetric and more general in order to check if they are bounded. If we find an unbounding input for every such construction, then this would imply that $\bmdeg_0(f) > \deg(f)$. Finally, we can also try to compute the dual witness that was discussed in Chapter 3 to show a separation between the two degrees.

% \section*{Acknowledgement}
% We would like to thank Dr. Rajat Mittal for guiding us throughout this project and giving us ideas on how to separate the two degrees, including both symmetrization and dual witness.

\bibliographystyle{ieeetr}
\bibliography{refs}
\end{document}
